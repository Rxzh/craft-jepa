{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a3c1bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch\n",
    "import webdataset\n",
    "import json\n",
    "import pandas as pd\n",
    "import io\n",
    "from mcap.reader import McapReader\n",
    "from mcap.reader import make_reader \n",
    "import cv2\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import os\n",
    "import time\n",
    "from IPython.display import display, Image, clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5b4a4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/vjepa/lib/python3.12/site-packages/webdataset/compat.py:379: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\"WebDataset(shardshuffle=...) is None; set explicitly to False or a number\")\n"
     ]
    }
   ],
   "source": [
    "SHARD_PATH = \"/Users/pierrebelamri/Downloads/shard-000639.tar\"\n",
    "\n",
    "dataset = webdataset.WebDataset(SHARD_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5a275e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_iterator = dataset.iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4403fa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_keys = []\n",
    "\n",
    "for sample in dataset:\n",
    "    jsonl_bytes = sample['.jsonl']\n",
    "    jsonl_data_string = jsonl_bytes.decode('utf-8')\n",
    "    df = pd.read_json(io.StringIO(jsonl_data_string), lines=True)\n",
    "\n",
    "    for row in df['keyboard'].apply(lambda x: x[\"keys\"]):\n",
    "        all_keys+=row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cbd863e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['key.keyboard.a', 'key.keyboard.caps.lock', 'key.keyboard.d',\n",
       "       'key.keyboard.e', 'key.keyboard.escape', 'key.keyboard.left.alt',\n",
       "       'key.keyboard.left.shift', 'key.keyboard.s', 'key.keyboard.space',\n",
       "       'key.keyboard.w', 'scancode.0'], dtype='<U23')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(all_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "402be6d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['key.keyboard.1',\n",
       " 'key.keyboard.2',\n",
       " 'key.keyboard.3',\n",
       " 'key.keyboard.4',\n",
       " 'key.keyboard.5',\n",
       " 'key.keyboard.6',\n",
       " 'key.keyboard.7',\n",
       " 'key.keyboard.8',\n",
       " 'key.keyboard.9',\n",
       " 'key.keyboard.w',\n",
       " 'key.keyboard.a',\n",
       " 'key.keyboard.s',\n",
       " 'key.keyboard.d',\n",
       " 'key.keyboard.space',\n",
       " 'key.keyboard.q',\n",
       " 'key.keyboard.f',\n",
       " 'key.keyboard.e',\n",
       " 'key.keyboard.key.keyboard.escape',\n",
       " 'key.keyboard.left.shift',\n",
       " 'key.keyboard.right.shift',\n",
       " 'key.keyboard.left.control']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hotbar \n",
    "[f'key.keyboard.{i}' for i in range(1,10)] + \\\n",
    "[f'key.keyboard.{x}' for x in ['w', 'a', 's', 'd', 'space']] + \\\n",
    "[f'key.keyboard.{x}' for x in ['q','f']] + \\\n",
    "[f'key.keyboard.{x}' for x in ['e']] + \\\n",
    "[f'key.keyboard.{x}' for x in ['key.keyboard.escape']] + \\\n",
    "[f'key.keyboard.{x}' for x in ['left.shift', 'right.shift', 'left.control', ]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939c46f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0=128\n",
    "x1=x0+10\n",
    "\n",
    "df['hotbar'][x0:x1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4586b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1d2ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for keyboard in df['keyboard']:\n",
    "    if 'key.keyboard.space' in keyboard['keys']:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd97589",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0524bf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['keyboard'][133])\n",
    "print(df['keyboard'][134])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c623ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['mouse'][133])\n",
    "print(df['mouse'][134])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b265a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hotbar'][133:135]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f187eccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mouse'][x0:x1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481d9208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571f3e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mouse_buttons =[]\n",
    "\n",
    "for sample in dataset:\n",
    "    jsonl_bytes = sample['.jsonl']\n",
    "    jsonl_data_string = jsonl_bytes.decode('utf-8')\n",
    "    df = pd.read_json(io.StringIO(jsonl_data_string), lines=True)\n",
    "\n",
    "    for row in df['mouse'].apply(lambda x: x[\"buttons\"]):\n",
    "        all_mouse_buttons+=row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09c6321",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(all_mouse_buttons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96d5ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyboard_states = df['keyboard'].values[:-1]\n",
    "\n",
    "# Create a (T-1, num_keys) zero array\n",
    "#key_presses_np = np.zeros((len(keyboard_states), len(self.KEYBOARD_KEYS)), dtype=np.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd3cdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyboard_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d31d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['yaw'].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5966e202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df['keyboard'] = df.apply(modify_keyboard_on_change, axis=1)\n",
    "\n",
    "\n",
    "df = df.drop(columns=['next_hotbar', 'hotbar_changed'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30a67bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Row 133 keyboard: {df.loc[133]['keyboard']}\")\n",
    "print(f\"Row 135 keyboard: {df.loc[134]['keyboard']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ce3c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hotbar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60f8baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4653d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Found sample with keys: {list(sample.keys())}\")\n",
    "print(\"The key '__key__' is the base name of the files.\")\n",
    "print(f\"Base name: {sample['__key__']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60a7c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_bytes = sample['.mp4']\n",
    "print(f\"Type: {type(video_bytes)}\")\n",
    "print(f\"Size: {len(video_bytes) / (1024*1024):.2f} MB\")\n",
    "print(\"This is the raw byte content of the video file.\")\n",
    "print(\"You would later feed this to a video-loading library (like decord or opencv).\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c7131d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jsonl_bytes = sample['.jsonl']\n",
    "jsonl_data_string = jsonl_bytes.decode('utf-8')\n",
    "df = pd.read_json(io.StringIO(jsonl_data_string), lines=True)\n",
    "\n",
    "print(f\"Loaded .jsonl into a pandas DataFrame with {len(df)} rows (actions).\")\n",
    "print(\"First 5 actions:\")\n",
    "print(df.head())\n",
    "print(\"\\nDataFrame Info:\")\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0ebef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1387d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(all_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd77961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6de30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcap_bytes = sample['.mcap']\n",
    "print(f\"Type: {type(mcap_bytes)}\")\n",
    "print(f\"Size: {len(mcap_bytes) / 1024:.2f} KB\\n\")\n",
    "\n",
    "\n",
    "mcap_file_like = io.BytesIO(mcap_bytes)\n",
    "reader = make_reader(mcap_file_like)\n",
    "\n",
    "print(\"Iterating through first 3 messages in the .mcap file...\")\n",
    "\n",
    "\n",
    "count = 0\n",
    "for schema, channel, message in reader.iter_messages():\n",
    "    #if count >= 30:\n",
    "    #    break\n",
    "    \n",
    "    if channel.topic == 'keyboard':\n",
    "\n",
    "    # Now we use the unpacked variables correctly:\n",
    "        print(f\"  [{count}] Topic: {channel.topic}\") \n",
    "        print(f\"      Schema: {schema.name}\")\n",
    "        print(f\"      Log Time: {message.log_time}\")\n",
    "    # message.data is the parsed dictionary\n",
    "        print(f\"      Data: {message.data}\") \n",
    "    count += 1\n",
    "\n",
    "if count == 0:\n",
    "    print(\"No messages found in the .mcap file.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f855ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "video_bytes = sample['.mp4']\n",
    "\n",
    "# --- 2. Create and write to a temporary file ---\n",
    "# We use tempfile to safely create a file\n",
    "# 'delete=False' means we have to manually delete it later\n",
    "with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_file:\n",
    "    temp_file.write(video_bytes)\n",
    "    temp_video_path = temp_file.name\n",
    "    print(f\"Video bytes saved to temporary file: {temp_video_path}\")\n",
    "\n",
    "# --- 3. Read the video with OpenCV ---\n",
    "cap = cv2.VideoCapture(temp_video_path)\n",
    "\n",
    "displaying = False\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open temporary video file.\")\n",
    "else:\n",
    "    print(\"\\nDisplaying all video frames (simulated video):\")\n",
    "    frame_count = 0\n",
    "    try:\n",
    "        while cap.isOpened() and frame_count < 1e10:\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                print(\"End of video.\")\n",
    "                break\n",
    "            \n",
    "            if displaying :\n",
    "                # b. Encode the frame as PNG bytes to display\n",
    "                _, png_data = cv2.imencode('.png', frame)\n",
    "\n",
    "                # c. Clear previous frame and display the new one\n",
    "                clear_output(wait=True)\n",
    "                display(Image(data=png_data.tobytes()))\n",
    "\n",
    "                # d. Wait a bit to simulate video playback\n",
    "                time.sleep(0.05) \n",
    "\n",
    "            frame_count += 1\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Video playback stopped by user.\")\n",
    "    finally:\n",
    "        # --- 5. Clean up ---\n",
    "        cap.release()\n",
    "        os.unlink(temp_video_path)\n",
    "        print(f\"Cleaned up temporary file: {temp_video_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bb383f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e741e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "png_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cca861",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f4329a",
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b5d6e7",
   "metadata": {},
   "source": [
    "# Dataset implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45a92000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('vjepa2')\n",
    "import logging\n",
    "import joblib\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "from vjepa2.app.vjepa_minecraft.vpt_dataset import init_vpt_dataloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05d7f1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO    ][2025-12-24 19:58:06][vjepa2.app.vjepa_minecraft.vpt_dataset][init_vpt_dataloader      ] Initializing VPT WebDataset loader from: /Users/pierrebelamri/Downloads/shard-000639.tar\n",
      "[INFO    ][2025-12-24 19:58:06][vjepa2.app.vjepa_minecraft.vpt_dataset][init_vpt_dataloader      ] Found 1 shards.\n",
      "[INFO    ][2025-12-24 19:58:06][vjepa2.app.vjepa_minecraft.vpt_dataset][init_vpt_dataloader      ] VPT WebDataset data loader created\n",
      "[INFO    ][2025-12-24 19:58:06][root                ][<module>                 ] Fetching one batch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/vjepa/lib/python3.12/site-packages/webdataset/compat.py:379: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\"WebDataset(shardshuffle=...) is None; set explicitly to False or a number\")\n",
      "/opt/miniconda3/envs/vjepa/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO    ][2025-12-24 19:58:10][root                ][<module>                 ] Batch loaded successfully!\n",
      "[INFO    ][2025-12-24 19:58:10][root                ][<module>                 ]   Video tensor shape: torch.Size([1, 8, 3, 256, 256])\n",
      "[INFO    ][2025-12-24 19:58:10][root                ][<module>                 ]   Actions tensor shape: torch.Size([1, 7, 38])\n",
      "[INFO    ][2025-12-24 19:58:10][root                ][<module>                 ]   States tensor shape: torch.Size([1, 8, 2])\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "DATA_PATH = SHARD_PATH\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "FRAMES_PER_CLIP = 16\n",
    "FPS = 5\n",
    "FRAMESKIP = 2  # This is the `tubelet_size`\n",
    "CROP_SIZE = 256\n",
    "NUM_WORKERS = 0 # Set to 0 for initial debugging, then increase\n",
    "\n",
    "# --- Initialize Loader ---\n",
    "try:\n",
    "    data_loader, _ = init_vpt_dataloader(\n",
    "        data_path=DATA_PATH,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        frames_per_clip=FRAMES_PER_CLIP,\n",
    "        fps=FPS,\n",
    "        crop_size=CROP_SIZE,\n",
    "        rank=0,\n",
    "        world_size=1,\n",
    "        frameskip=FRAMESKIP,\n",
    "        num_workers=NUM_WORKERS,\n",
    "    )\n",
    "\n",
    "    logger.info(\"Fetching one batch...\")\n",
    "    batch = next(iter(data_loader))\n",
    "\n",
    "    video_tensor = batch['video_frames']\n",
    "    actions_tensor = batch['actions']\n",
    "    states_tensor = batch['states']\n",
    "\n",
    "    logger.info(f\"Batch loaded successfully!\")\n",
    "\n",
    "    # (B, T, C, H, W)\n",
    "    logger.info(f\"  Video tensor shape: {video_tensor.shape}\") \n",
    "\n",
    "    # (B, T_actions, D_actions)\n",
    "    # T_actions = (FRAMES_PER_CLIP / FRAMESKIP) - 1 = (16/2) - 1 = 7\n",
    "    logger.info(f\"  Actions tensor shape: {actions_tensor.shape}\")\n",
    "\n",
    "    # (B, T_states, D_states)\n",
    "    # T_states = FRAMES_PER_CLIP / FRAMESKIP = 16/2 = 8\n",
    "    logger.info(f\"  States tensor shape: {states_tensor.shape}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    logger.error(f\"Error: {e}\")\n",
    "    logger.error(\"Please update the DATA_PATH variable in the __main__ block.\")\n",
    "except KeyError as e:\n",
    "     logger.error(f\"Error: Missing data key {e}.\")\n",
    "     logger.error(\"This could be a column in the DataFrame (e.g., 'hotbar')\")\n",
    "     logger.error(\"OR a key in a dict (e.g., 'dx' in the 'mouse' column).\")\n",
    "     logger.error(\"Please verify all keys in vpt_states_to_diffs().\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"An unexpected error occurred: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5f8e039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 38])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a84d9e81",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'actions_tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mactions_tensor\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'actions_tensor' is not defined"
     ]
    }
   ],
   "source": [
    "actions_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e25522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4ba01d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "756ad36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([f'key.keyboard.{i}' for i in range(1,10)] + \\\n",
    "    [f'key.keyboard.{x}' for x in ['w', 'a', 's', 'd', 'space']] + \\\n",
    "    [f'key.keyboard.{x}' for x in ['q','f']] + \\\n",
    "    [f'key.keyboard.{x}' for x in ['e']] + \\\n",
    "    [f'key.keyboard.{x}' for x in ['escape']] + \\\n",
    "    [f'key.keyboard.{x}' for x in ['left.shift', 'right.shift', 'left.control', ]] )\\\n",
    "+len([0, 1, 2])  \\\n",
    "#+9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5868391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24de876f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e59ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in scaler_fit_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfd284d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fd1fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    logger.info(\"Starting scaler fitting loop...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(scaler_fit_loader, desc=\"Fitting Scaler\"):\n",
    "            actions_batch_tensor = batch['actions']\n",
    "            continuous_actions_tensor = actions_batch_tensor[:, :, :4]\n",
    "            continuous_actions_flat = continuous_actions_tensor.reshape(-1, 4)\n",
    "            continuous_actions_np = continuous_actions_flat.cpu().numpy()\n",
    "            if len(continuous_actions_np) > 0:\n",
    "                scaler.partial_fit(continuous_actions_np)\n",
    "\n",
    "    joblib.dump(scaler, scaler_save_path)\n",
    "    \n",
    "    logger.info(\"=\" * 30)\n",
    "    logger.info(f\"Scaler fitting complete and saved to: {scaler_save_path}\")\n",
    "    logger.info(f\"  Mean: {scaler.mean_}\")\n",
    "    logger.info(f\"  Scale (StdDev): {scaler.scale_}\")\n",
    "    logger.info(\"=\" * 30)\n",
    "    \n",
    "    return scaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac48912e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO    ][2025-12-24 21:02:42][root                ][fit_action_scaler_fast   ] Initializing dataloader to fit scaler from: /Users/pierrebelamri/Downloads/shard-000639.tar\n",
      "[INFO    ][2025-12-24 21:02:42][vjepa2.app.vjepa_minecraft.vpt_dataset][init_vpt_dataloader      ] Initializing VPT WebDataset loader from: /Users/pierrebelamri/Downloads/shard-000639.tar\n",
      "[INFO    ][2025-12-24 21:02:42][vjepa2.app.vjepa_minecraft.vpt_dataset][init_vpt_dataloader      ] Found 1 shards.\n",
      "[INFO    ][2025-12-24 21:02:42][vjepa2.app.vjepa_minecraft.vpt_dataset][init_vpt_dataloader      ] VPT WebDataset data loader created\n",
      "[INFO    ][2025-12-24 21:02:42][root                ][fit_action_scaler_fast   ] Starting fast scaler fitting loop (Sufficient Statistics)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting Stats: 0it [00:00, ?it/s]/opt/miniconda3/envs/vjepa/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "Collecting Stats: 315it [14:53:04, 170.11s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 105\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m         \u001b[43mfit_action_scaler_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSCALER_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m         \u001b[38;5;66;03m# Verify\u001b[39;00m\n\u001b[32m    108\u001b[39m         logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoading scaler from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSCALER_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for verification...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 51\u001b[39m, in \u001b[36mfit_action_scaler_fast\u001b[39m\u001b[34m(data_path, scaler_save_path)\u001b[39m\n\u001b[32m     48\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mStarting fast scaler fitting loop (Sufficient Statistics)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscaler_fit_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCollecting Stats\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Extract and reshape\u001b[39;49;00m\n\u001b[32m     53\u001b[39m \u001b[43m        \u001b[49m\u001b[43mactions_batch\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mactions\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcont_actions\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdouble\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Cast to double for precision\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/vjepa/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/vjepa/lib/python3.12/site-packages/torch/utils/data/dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/vjepa/lib/python3.12/site-packages/torch/utils/data/dataloader.py:788\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    787\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    790\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/vjepa/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:33\u001b[39m, in \u001b[36m_IterableDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m         data.append(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset_iter\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m     35\u001b[39m         \u001b[38;5;28mself\u001b[39m.ended = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/vjepa/lib/python3.12/site-packages/webdataset/pipeline.py:105\u001b[39m, in \u001b[36mDataPipeline.iterator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.repetitions):\n\u001b[32m    104\u001b[39m     count = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterator1\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/vjepa/lib/python3.12/site-packages/webdataset/filters.py:429\u001b[39m, in \u001b[36m_select\u001b[39m\u001b[34m(data, predicate)\u001b[39m\n\u001b[32m    418\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_select\u001b[39m(data, predicate):\n\u001b[32m    419\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    420\u001b[39m \u001b[33;03m    Select samples based on a predicate.\u001b[39;00m\n\u001b[32m    421\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    427\u001b[39m \u001b[33;03m        Samples that satisfy the predicate.\u001b[39;00m\n\u001b[32m    428\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m429\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/vjepa/lib/python3.12/site-packages/webdataset/filters.py:522\u001b[39m, in \u001b[36m_map\u001b[39m\u001b[34m(data, f, handler)\u001b[39m\n\u001b[32m    520\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[32m    521\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m522\u001b[39m         result = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    523\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exn:\n\u001b[32m    524\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m handler(exn):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/craft-jepa/vjepa2/app/vjepa_minecraft/vpt_dataset.py:254\u001b[39m, in \u001b[36mProcessVPT.__call__\u001b[39m\u001b[34m(self, sample)\u001b[39m\n\u001b[32m    252\u001b[39m \u001b[38;5;66;03m# --- 2. Load Data ---\u001b[39;00m\n\u001b[32m    253\u001b[39m vr.seek(\u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m254\u001b[39m buffer = \u001b[43mvr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m.asnumpy()  \u001b[38;5;66;03m# (T, H, W, C)\u001b[39;00m\n\u001b[32m    256\u001b[39m \u001b[38;5;66;03m# Get the raw sequence of actions corresponding to frames\u001b[39;00m\n\u001b[32m    257\u001b[39m \u001b[38;5;66;03m# We do NOT subsample the DF yet, we need the intermediate rows for aggregation\u001b[39;00m\n\u001b[32m    258\u001b[39m raw_window_df = actions_df.iloc[indices].reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/vjepa/lib/python3.12/site-packages/decord/video_reader.py:175\u001b[39m, in \u001b[36mVideoReader.get_batch\u001b[39m\u001b[34m(self, indices)\u001b[39m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    174\u001b[39m indices = _nd.array(\u001b[38;5;28mself\u001b[39m._validate_indices(indices))\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m arr = \u001b[43m_CAPI_VideoReaderGetBatch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m bridge_out(arr)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/vjepa/lib/python3.12/site-packages/decord/_ffi/_ctypes/function.py:173\u001b[39m, in \u001b[36mFunctionBase.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    171\u001b[39m ret_val = DECORDValue()\n\u001b[32m    172\u001b[39m ret_tcode = ctypes.c_int()\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m check_call(\u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDECORDFuncCall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtcodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mret_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mret_tcode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    176\u001b[39m _ = temp_args\n\u001b[32m    177\u001b[39m _ = args\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('vjepa2')\n",
    "import logging\n",
    "import joblib\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "from vjepa2.app.vjepa_minecraft.vpt_dataset import init_vpt_dataloader\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "SCALER_PATH = \"vpt_action_scaler.pkl\"\n",
    "\n",
    "# OPTIMIZATION TIP: \n",
    "# Batch size 1 is very slow for statistics gathering. \n",
    "# Increase this to max out your GPU memory (e.g., 64, 128, 256).\n",
    "FIT_BATCH_SIZE = 4 \n",
    "# Increase workers to prefetch data while GPU computes\n",
    "NUM_WORKERS = 0 \n",
    "\n",
    "def fit_action_scaler_fast(data_path, scaler_save_path):\n",
    "    logger.info(f\"Initializing dataloader to fit scaler from: {data_path}\")\n",
    "\n",
    "    scaler_fit_loader, _ = init_vpt_dataloader(\n",
    "        data_path=data_path,\n",
    "        batch_size=FIT_BATCH_SIZE,\n",
    "        action_scaler=None,\n",
    "        frames_per_clip=64,\n",
    "        fps=5,\n",
    "        frameskip=2,\n",
    "        crop_size=256,\n",
    "        rank=0,\n",
    "        world_size=1,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    # Initialize accumulators on the device (GPU if available)\n",
    "    # Assuming 4 continuous action dimensions based on your snippet\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "    total_count = 0\n",
    "    total_sum = torch.zeros(4, device=device, dtype=torch.float64) # Use float64 for precision\n",
    "    total_sq_sum = torch.zeros(4, device=device, dtype=torch.float64)\n",
    "\n",
    "    logger.info(\"Starting fast scaler fitting loop (Sufficient Statistics)...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(scaler_fit_loader, desc=\"Collecting Stats\"):\n",
    "            # Extract and reshape\n",
    "            actions_batch = batch['actions'].to(device)\n",
    "            cont_actions = actions_batch[..., :4].reshape(-1, 4).double() # Cast to double for precision\n",
    "\n",
    "            if cont_actions.shape[0] > 0:\n",
    "                # Accumulate stats purely in PyTorch\n",
    "                total_count += cont_actions.shape[0]\n",
    "                total_sum += torch.sum(cont_actions, dim=0)\n",
    "                total_sq_sum += torch.sum(cont_actions ** 2, dim=0)\n",
    "\n",
    "    # --- Final Calculation ---\n",
    "    # Calculate Mean: E[X]\n",
    "    mean = total_sum / total_count\n",
    "    \n",
    "    # Calculate variance: E[X^2] - (E[X])^2\n",
    "    variance = (total_sq_sum / total_count) - (mean ** 2)\n",
    "    \n",
    "    # handle precision issues\n",
    "    variance = torch.clamp(variance, min=0.0)\n",
    "    std_dev = torch.sqrt(variance)\n",
    "\n",
    "    # Move to CPU/Numpy for Scikit-Learn\n",
    "    mean_np = mean.cpu().numpy()\n",
    "    std_np = std_dev.cpu().numpy()\n",
    "    var_np = variance.cpu().numpy()\n",
    "\n",
    "    # --- Manually Inject into StandardScaler ---\n",
    "    # We create the object and force-feed the calculated attributes\n",
    "    scaler = StandardScaler()\n",
    "    scaler.mean_ = mean_np\n",
    "    scaler.scale_ = std_np\n",
    "    scaler.var_ = var_np\n",
    "    scaler.n_samples_seen_ = total_count\n",
    "    \n",
    "    # Important: Set copy=True and with_mean/std=True to ensure it works correctly\n",
    "    scaler.with_mean = True\n",
    "    scaler.with_std = True\n",
    "    scaler.copy = True\n",
    "\n",
    "    # Save\n",
    "    joblib.dump(scaler, scaler_save_path)\n",
    "    \n",
    "    logger.info(\"=\" * 30)\n",
    "    logger.info(f\"Scaler fitting complete and saved to: {scaler_save_path}\")\n",
    "    logger.info(f\"  Total Samples: {total_count}\")\n",
    "    logger.info(f\"  Mean: {scaler.mean_}\")\n",
    "    logger.info(f\"  Scale (StdDev): {scaler.scale_}\")\n",
    "    logger.info(\"=\" * 30)\n",
    "    \n",
    "    return scaler\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        fit_action_scaler_fast(DATA_PATH, SCALER_PATH)\n",
    "        \n",
    "        # Verify\n",
    "        logger.info(f\"Loading scaler from {SCALER_PATH} for verification...\")\n",
    "        loaded_scaler = joblib.load(SCALER_PATH)\n",
    "        # Test a transform to ensure internal state is valid\n",
    "        dummy_data = np.random.rand(5, 4)\n",
    "        scaled_dummy = loaded_scaler.transform(dummy_data)\n",
    "        logger.info(\"Verification transform successful.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unexpected error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ccdb63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
