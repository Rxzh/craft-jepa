{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a21b9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "import joblib\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "sys.path.append('vjepa2')\n",
    "# Import the dataloader function from your dataset file\n",
    "from vjepa2.app.vjepa_minecraft.vpt_dataset import init_vpt_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4af7272",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb908c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# --- Configuration ---\n",
    "# !! IMPORTANT: Update this path to ALL your shards !!\n",
    "DATA_PATH = \"shard-000024.tar\" \n",
    "SCALER_PATH = \"vpt_action_scaler.pkl\" # Path to save the fitted scaler\n",
    "\n",
    "# Use a large batch size for faster iteration\n",
    "FIT_BATCH_SIZE = 128\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "def fit_action_scaler(data_path, scaler_save_path):\n",
    "    \"\"\"\n",
    "    Iterates through the dataset to fit a StandardScaler on the\n",
    "    continuous action dimensions.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Initializing dataloader to fit scaler from: {data_path}\")\n",
    "\n",
    "    # 1. Initialize the dataloader WITHOUT a scaler\n",
    "    # This means the 'actions' tensor will contain un-normalized data\n",
    "    scaler_fit_loader, _ = init_vpt_dataloader(\n",
    "        data_path=data_path,\n",
    "        batch_size=FIT_BATCH_SIZE,\n",
    "        action_scaler=None,  # <-- Explicitly pass None\n",
    "        # Use simple settings for fitting\n",
    "        frames_per_clip=200,\n",
    "        fps=20,\n",
    "        frameskip=1,\n",
    "        crop_size=256,\n",
    "        rank=0,\n",
    "        world_size=1,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        drop_last=False, # We want to see all data\n",
    "    )\n",
    "\n",
    "    # 2. Initialize the scaler\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # 3. Iterate through the dataset and fit the scaler\n",
    "    logger.info(\"Starting scaler fitting loop...\")\n",
    "    \n",
    "    # We use a torch.no_grad() context, as we are not training\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(scaler_fit_loader, desc=\"Fitting Scaler\"):\n",
    "            # batch['actions'] shape is (B, T_actions, D_actions)\n",
    "            # D_actions = 4 + num_keys + num_buttons + hotbar + gui\n",
    "            actions_batch_tensor = batch['actions']\n",
    "\n",
    "            # Extract the first 4 columns: [mouse_dx, mouse_dy, yaw_diff, pitch_diff]\n",
    "            continuous_actions_tensor = actions_batch_tensor[:, :, :4]\n",
    "            \n",
    "            # Reshape to (B * T_actions, 4) for the scaler\n",
    "            continuous_actions_flat = continuous_actions_tensor.reshape(-1, 4)\n",
    "            \n",
    "            # Move to CPU and convert to numpy\n",
    "            continuous_actions_np = continuous_actions_flat.cpu().numpy()\n",
    "\n",
    "            # Fit the scaler incrementally on the batch\n",
    "            if len(continuous_actions_np) > 0:\n",
    "                scaler.partial_fit(continuous_actions_np)\n",
    "\n",
    "    # 4. Save the fitted scaler to disk\n",
    "    joblib.dump(scaler, scaler_save_path)\n",
    "    \n",
    "    logger.info(\"=\" * 30)\n",
    "    logger.info(f\"Scaler fitting complete and saved to: {scaler_save_path}\")\n",
    "    logger.info(f\"  Mean: {scaler.mean_}\")\n",
    "    logger.info(f\"  Scale (StdDev): {scaler.scale_}\")\n",
    "    logger.info(\"=\" * 30)\n",
    "    \n",
    "    return scaler\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        fit_action_scaler(DATA_PATH, SCALER_PATH)\n",
    "        \n",
    "        # --- Example of loading it back ---\n",
    "        logger.info(f\"Loading scaler from {SCALER_PATH} for verification...\")\n",
    "        loaded_scaler = joblib.load(SCALER_PATH)\n",
    "        logger.info(f\"Loaded Mean: {loaded_scaler.mean_}\")\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        logger.error(f\"Error: {e}\")\n",
    "        logger.error(\"Please update the DATA_PATH variable in fit_scaler.py\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unexpected error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99176f18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e8a0fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13c0b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe81202",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
